"""
Interaktives Chat-Script: Quittungen aus DB mit lokalem LLM analysieren

Dieses Script:
1. LÃ¤dt Quittungen aus der SQLite-Datenbank
2. Konvertiert sie ins RAG-Format (optional)
3. ErmÃ¶glicht interaktive Fragen mit dem lokalen LLM
"""

import asyncio
import sys
from pathlib import Path

# Datenbank-Importe
from sqlmodel import Session, select
from services.database import engine, init_db
from models.db_models import ReceiptDB, LineItemDB

# LLM-Importe
from services.ollama_service import generate_chat_response, check_ollama_status
from services.rag_service import init_rag, add_receipt_to_rag, receipt_to_document, get_context_for_query
from models.receipt import Receipt, LineItem


def convert_db_receipt_to_rag_receipt(db_receipt: ReceiptDB, line_items: list) -> Receipt:
    """Konvertiert ein ReceiptDB zu einem Receipt (fÃ¼r RAG)."""
    # Line Items konvertieren
    rag_line_items = [
        LineItem(
            description=item.description,
            quantity=1.0,  # Standard, da wir das nicht in DB haben
            total_price=item.amount,
            category=None  # KÃ¶nnten wir aus description ableiten
        )
        for item in line_items
    ]
    
    # Receipt erstellen
    rag_receipt = Receipt(
        vendor_name=db_receipt.vendor_name,
        date=db_receipt.date.isoformat() if db_receipt.date else None,
        total=db_receipt.total_amount,
        tax=db_receipt.tax_amount,
        currency=db_receipt.currency,
        category=db_receipt.category,
        line_items=rag_line_items
    )
    
    return rag_receipt


def load_receipts_from_db() -> list:
    """LÃ¤dt alle Quittungen aus der Datenbank."""
    init_db()
    with Session(engine) as session:
        statement = select(ReceiptDB)
        receipts = session.exec(statement).all()
        
        result = []
        for receipt in receipts:
            # Line Items laden
            items_statement = select(LineItemDB).where(LineItemDB.receipt_id == receipt.id)
            items = session.exec(items_statement).all()
            result.append((receipt, list(items)))
        
        return result


def format_receipts_for_context(receipts_data: list) -> str:
    """Formatiert Quittungen als Text-Kontext fÃ¼r das LLM."""
    context_parts = []
    
    for receipt, items in receipts_data:
        items_text = "\n".join([f"  - {item.description}: {item.amount}â‚¬" for item in items])
        
        receipt_text = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Quittung #{receipt.id}
Vendor: {receipt.vendor_name}
Datum: {receipt.date.isoformat() if receipt.date else 'unbekannt'}
Gesamtbetrag: {receipt.total_amount}â‚¬
MwSt: {receipt.tax_amount}â‚¬
Kategorie: {receipt.category or 'unbekannt'}
WÃ¤hrung: {receipt.currency}

Audit-Flags:
  - Duplikat: {'âœ“' if receipt.flag_duplicate else 'âœ—'}
  - VerdÃ¤chtig: {'âœ“' if receipt.flag_suspicious else 'âœ—'}
  - MwSt fehlt: {'âœ“' if receipt.flag_missing_vat else 'âœ—'}
  - Rechenfehler: {'âœ“' if receipt.flag_math_error else 'âœ—'}

Positionen:
{items_text}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        context_parts.append(receipt_text)
    
    return "\n".join(context_parts)


async def chat_loop(receipts_data: list):
    """Haupt-Chat-Loop."""
    print("\n" + "="*60)
    print("ğŸ’¬ CHAT MIT LOKALEM LLM")
    print("="*60)
    print(f"ğŸ“Š {len(receipts_data)} Quittungen geladen")
    print("\nğŸ’¡ Beispiel-Fragen:")
    print("   - 'Wie viel habe ich insgesamt ausgegeben?'")
    print("   - 'Zeige mir alle verdÃ¤chtigen Quittungen'")
    print("   - 'Was waren meine Top-Ausgaben?'")
    print("   - 'Wie viel fÃ¼r Alkohol?'")
    print("   - 'Welche Quittungen haben Rechenfehler?'")
    print("\nTipp: Tippe 'exit' zum Beenden\n")
    
    history = []
    
    while True:
        try:
            question = input("â“ Deine Frage: ").strip()
            
            if not question:
                continue
            
            if question.lower() in ['exit', 'quit', 'q', 'beenden']:
                print("\nğŸ‘‹ Auf Wiedersehen!")
                break
            
            print("\nğŸ¤” Denke nach...\n")
            
            # Kontext fÃ¼r LLM erstellen
            context = format_receipts_for_context(receipts_data)
            
            # Antwort generieren
            response = await generate_chat_response(
                question=question,
                context=context,
                history=history
            )
            
            print("ğŸ¤– Antwort:")
            print(response)
            print("\n" + "-"*60 + "\n")
            
            # History aktualisieren (optional)
            history.append({"role": "user", "content": question})
            history.append({"role": "assistant", "content": response})
            
            # History begrenzen (letzte 10 Nachrichten)
            if len(history) > 10:
                history = history[-10:]
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Beendet durch Benutzer")
            break
        except Exception as e:
            print(f"\nâŒ Fehler: {e}")
            print("Versuche es erneut...\n")


def main():
    """Hauptfunktion."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Chat mit Quittungen aus DB via lokales LLM")
    parser.add_argument("--load-rag", action="store_true", 
                       help="Lade Quittungen auch in RAG-DB (fÃ¼r semantische Suche)")
    parser.add_argument("--limit", type=int, default=None,
                       help="Limit Anzahl Quittungen (fÃ¼r Tests)")
    
    args = parser.parse_args()
    
    print("ğŸ” Lade Quittungen aus Datenbank...")
    receipts_data = load_receipts_from_db()
    
    if not receipts_data:
        print("âŒ Keine Quittungen gefunden!")
        print("   Tipp: FÃ¼hre zuerst backend/seed.py aus")
        sys.exit(1)
    
    if args.limit:
        receipts_data = receipts_data[:args.limit]
        print(f"ğŸ“Š Limitiert auf {len(receipts_data)} Quittungen")
    
    print(f"âœ… {len(receipts_data)} Quittungen geladen")
    
    # Optional: In RAG-DB laden
    if args.load_rag:
        print("\nğŸ”„ Lade Quittungen in RAG-DB...")
        init_rag()
        
        for receipt, items in receipts_data:
            rag_receipt = convert_db_receipt_to_rag_receipt(receipt, items)
            receipt_id = f"db_{receipt.id}"
            add_receipt_to_rag(rag_receipt, receipt_id)
        
        print(f"âœ… {len(receipts_data)} Quittungen in RAG-DB geladen")
        print("   (Semantische Suche jetzt verfÃ¼gbar)")
    
    # Ollama Status prÃ¼fen
    print("\nğŸ” PrÃ¼fe Ollama...")
    status = check_ollama_status()
    
    if not status.get("available", False):
        print("âŒ Ollama ist nicht verfÃ¼gbar!")
        print("   Stelle sicher, dass Ollama lÃ¤uft:")
        print("   ollama serve")
        print("\n   Und dass die Modelle installiert sind:")
        print("   ollama pull llama3.2")
        sys.exit(1)
    
    print(f"âœ… Ollama lÃ¤uft - Modell: {status.get('chat_model', 'unbekannt')}")
    
    # Chat starten
    asyncio.run(chat_loop(receipts_data))


if __name__ == "__main__":
    main()


