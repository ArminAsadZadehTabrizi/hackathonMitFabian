#!/bin/bash
# Quick-Start: Chat mit Quittungen via LLM

echo "ü§ñ Quick-Start: Chat mit lokalem LLM"
echo ""

# Pr√ºfe Ollama
echo "üîç Pr√ºfe Ollama..."
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "‚ö†Ô∏è  Ollama l√§uft nicht!"
    echo ""
    echo "Starte Ollama in einem anderen Terminal:"
    echo "   ollama serve"
    echo ""
    read -p "Trotzdem fortfahren? (y/n) " -n 1 -r
    echo ""
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
else
    echo "‚úÖ Ollama l√§uft"
fi

echo ""
echo "üöÄ Starte Chat..."
echo ""

python3 chat_with_db_receipts.py --load-rag


