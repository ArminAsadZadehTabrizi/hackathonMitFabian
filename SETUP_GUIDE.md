# ğŸš€ Small Business Auto-Bookkeeper - Setup Guide

> Hackathon 2 â€“ Local AI Edition

## Schnellstart

```bash
# Im Projektverzeichnis:
./start.sh
```

Das startet automatisch:
- ğŸ§  AI-Backend auf http://localhost:8000
- ğŸ“Š Frontend auf http://localhost:8082
- ğŸ¤– PrÃ¼ft/startet Ollama

---

## Voraussetzungen

### 1. Node.js (>=20)
```bash
node --version  # Sollte v20+ zeigen
```

### 2. Python 3.11
```bash
python3.11 --version
# Falls nicht vorhanden:
brew install python@3.11
```

### 3. Ollama
```bash
# Installation
brew install ollama

# Starten
ollama serve

# Modelle laden (einmalig)
ollama pull llama3.2
ollama pull llama3.2-vision  # Optional, fÃ¼r Bild-Analyse
```

---

## Manuelle Installation

### Frontend
```bash
cd frontend
npm install
npm run dev
```

### AI-Backend
```bash
cd ai-backend
source venv/bin/activate
pip install -r requirements.txt
python main.py
```

### Datenbank mit Testdaten fÃ¼llen
```bash
cd ai-backend
source venv/bin/activate
python seed_db.py
```

---

## Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend                             â”‚
â”‚                    (Next.js + MUI)                          â”‚
â”‚                   http://localhost:8082                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ API Calls
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       AI-Backend                             â”‚
â”‚                   (FastAPI + Python)                         â”‚
â”‚                   http://localhost:8000                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     SQLite Database     â”‚         ChromaDB (RAG)            â”‚
â”‚    (receipts.db)        â”‚        (chroma_db/)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Ollama                               â”‚
â”‚                   (Local LLM Server)                         â”‚
â”‚                   http://localhost:11434                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    llama3.2 (Chat)      â”‚     llama3.2-vision (OCR)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## API Endpoints

### Receipts
- `GET /api/receipts` - Alle Quittungen
- `GET /api/receipts?receiptId=1` - Einzelne Quittung
- `POST /api/ingest` - Neue Quittung erstellen

### Analytics
- `GET /api/analytics/summary` - Dashboard-Ãœbersicht
- `GET /api/analytics/monthly` - Monatliche Daten
- `GET /api/analytics/vendors` - Vendor-Statistiken
- `GET /api/analytics/categories` - Kategorie-Ausgaben

### Audit
- `GET /api/audit` - Alle Audit-Findings

### Chat (AI Auditor)
- `POST /api/chat/query` - Frage an AI-Auditor
- `POST /api/chat` - Chat mit RAG-Kontext

### Bild-Extraktion
- `POST /api/extract` - Quittung aus Bild extrahieren
- `POST /api/extract/upload` - Bild hochladen und analysieren

---

## Features

### âœ… Pillar 1 - Auto-Bookkeeper Engine
- [x] Receipt Ingestion (JSON + Bild)
- [x] LLM-basierte Datenextraktion
- [x] Kategorisierung
- [x] Audit-Flags (Duplikate, MwSt, Rechenfehler, VerdÃ¤chtige Items)

### âœ… Pillar 2 - Financial Command Center
- [x] Receipts Page (Tabelle + Details)
- [x] Analytics Dashboard
- [x] Vendor Analytics
- [x] Audit Findings

### âœ… Pillar 3 - AI Auditor Chat
- [x] Natural Language Queries
- [x] RAG mit ChromaDB
- [x] PrÃ¤zise Berechnungen (Python)
- [x] LLM-formulierte Antworten

---

## Technologien

### Frontend
- Next.js 15
- React 19
- MUI v7 (Premium Template)
- TypeScript

### Backend
- FastAPI
- SQLModel + SQLite
- ChromaDB (Vector DB)
- Sentence Transformers (Embeddings)

### Local AI
- Ollama
- llama3.2 (Chat)
- llama3.2-vision (Bild-Analyse)

---

## Troubleshooting

### Port bereits belegt
```bash
# Backend Port 8000
lsof -i :8000
kill -9 <PID>

# Frontend Port 8082
lsof -i :8082
kill -9 <PID>
```

### Ollama nicht erreichbar
```bash
# PrÃ¼fen ob Ollama lÃ¤uft
pgrep -f ollama

# Manuell starten
ollama serve
```

### Dependency-Probleme
```bash
# Frontend
cd frontend && rm -rf node_modules && npm install

# Backend
cd ai-backend && rm -rf venv
/opt/homebrew/opt/python@3.11/bin/python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## Team

Hackathon 2 - 2025

